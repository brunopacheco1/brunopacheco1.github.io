+++ 
draft = false
date = 2024-02-22T22:00:00+01:00
title = "Using OpenAI for Webcrawling"
slug = "" 
tags = []
categories = []
thumbnail = "images/tn.png"
description = ""
+++

One of my first experiences in software development was webcrawling on [Cortex Inteligence](https://www.cortex-intelligence.com/). It was a great opportunity to learn Java. It also improved a lot my problem solving skills, because we had a lot of content to extract from internet, and it had to be fast, constant and reliable. Every day we needed to come up with different solutions.

I brought that experience to the next job at ECAD. As it is a company to manage song copyrights, it was important to monitor concerts or any cultural event slightly related to music. Here again webcrawling was crucial to reduce a lot of human work, so the auditors could focus on analysing cases, instead of searching for them. We built several bots to fulfill that tedius tasks.

The problem is that each website out there is unique, with different constrainst and different way to expose data. At the same time, developing a bot is a quite consuming task, requiring dedicated people to develop new and fix existing bots. The same code could easly break multiple times in a month, just because of unexpected tag or data type, or the site can completelly change, or the source detects the bot and kills the connection, and so one.

Back then, there was a dream of a generic code that could just read a page and export the data, with simple instructions. And now we have mature enough technologies and providers to fulfill this gap. And that is what I am going to try now, using ChatGPT.



**See you | Bis geschwënn | Até mais | À bientôt**
